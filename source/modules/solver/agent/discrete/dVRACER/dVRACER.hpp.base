#pragma once

#include "modules/distribution/univariate/normal/normal.hpp"
#include "modules/problem/reinforcementLearning/discrete/discrete.hpp"
#include "modules/solver/agent/discrete/discrete.hpp"

__startNamespace__;

class __className__ : public __parentClassName__
{
  public:
  /**
   * @brief Pointer to training the actor network
   */
  std::vector<learner::DeepSupervisor *> _criticPolicyLearner;

  /**
   * @brief Korali experiment for obtaining the agent's action
   */
  std::vector<korali::Experiment> _criticPolicyExperiment;

  /**
   * @brief Pointer to actor's experiment problem
   */
  std::vector<problem::SupervisedLearning *> _criticPolicyProblem;

  /**
   * @brief Update the V-target or current and previous experiences in the episode
   * @param expId Current Experience Id
   */
  void updateVtbc(size_t expId);

  /**
   * @brief Calculates the gradients for the policy/critic neural network
   * @param miniBatch The indexes of the experience mini batch
   */
  void calculatePolicyGradients(const std::vector<std::pair<size_t,size_t>> &miniBatch, const std::vector<policy_t> &policy, const size_t policyIdx);

  void runPolicy(const std::vector<std::vector<std::vector<float>>> &stateBatch, std::vector<policy_t> &policy, const size_t policyIdx = 0) override;

  knlohmann::json getAgentPolicy() override;
  void setAgentPolicy(const knlohmann::json &hyperparameters) override;
  void trainPolicy() override;
  void printAgentInformation() override;
  void initializeAgent() override;
};

__endNamespace__;
